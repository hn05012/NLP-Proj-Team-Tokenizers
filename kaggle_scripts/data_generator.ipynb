{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n!pip install stackapi pandas pyarrow --quiet","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-23T02:23:56.255401Z","iopub.execute_input":"2025-06-23T02:23:56.255712Z","iopub.status.idle":"2025-06-23T02:24:00.046872Z","shell.execute_reply.started":"2025-06-23T02:23:56.255682Z","shell.execute_reply":"2025-06-23T02:24:00.045387Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\nimport re\nimport time\nimport nltk\nfrom datetime import datetime, timedelta\nfrom stackapi import StackAPI\nfrom nltk.tokenize import sent_tokenize\n\nnltk.download('punkt')\n\n# Config\nTOTAL_QUESTIONS = 100000\nPAGE_SIZE = 50\nTAGS = ['python']\nOUTPUT_PATH = \"/kaggle/working/simple_python_qa_rag_dataset.json\"\n\n\n# Utility functions\ndef clean_text(text):\n    text = re.sub(r'<[^>]+>', '', text)\n    text = re.sub(r'\\s+', ' ', text)\n    return text.strip()\n\ndef count_words(text):\n    return len(text.split())\n\ndef count_sentences(text):\n    return len(sent_tokenize(text))\n\ndef contains_code_block(text):\n    return '<pre>' in text or '```' in text\n\ndef is_simple_qa(q, a):\n    return (\n        count_words(q) <= 20 and\n        count_words(a) <= 30 and\n        count_sentences(a) <= 2 and\n        not contains_code_block(a)\n    )\n\n# StackAPI init\nsite = StackAPI('stackoverflow',  max_retries=5)\nsite.page_size = PAGE_SIZE\nsite.max_pages = TOTAL_QUESTIONS // PAGE_SIZE + 1\n\nstart_date = datetime.now() - timedelta(days=2920)\nend_date = datetime.now()\n\nprint(f\"Fetching simple Python Q&A pairs (max {TOTAL_QUESTIONS})...\")\n\n# Phase 1: Get question IDs\nquestion_ids = []\npage = 1\nwhile len(question_ids) < TOTAL_QUESTIONS * 2:  # Oversample for filtering\n    try:\n        questions = site.fetch('questions',\n            tagged=TAGS,\n            sort='votes',\n            order='desc',\n            fromdate=int(start_date.timestamp()),\n            todate=int(end_date.timestamp()),\n            page=page,\n            filter='withbody'\n        )\n        if not questions['items']:\n            break\n\n        question_ids.extend([q['question_id'] for q in questions['items']])\n        print(f\"Collected {len(question_ids)} question IDs...\")\n        page += 1\n        time.sleep(1)\n\n    except Exception as e:\n        print(f\"Error fetching page {page}: {str(e)}\")\n        break\n\n# Phase 2: Process Q&As\nprocessed_data = []\nbatch_size = 10\nfor i in range(0, len(question_ids), batch_size):\n    batch_ids = question_ids[i:i+batch_size]\n    if len(processed_data) >= TOTAL_QUESTIONS:\n        break\n\n    try:\n        questions = site.fetch('questions', ids=batch_ids, filter='withbody')\n        for question in questions['items']:\n            try:\n                answers = site.fetch(f'questions/{question[\"question_id\"]}/answers',\n                    filter='withbody',\n                    sort='votes',\n                    order='desc'\n                )['items']\n\n                if len(answers) < 1:\n                    continue\n\n                best_answer = answers[0]\n                q_text = clean_text(question['title'])\n                a_text = clean_text(best_answer['body'])\n\n                if not is_simple_qa(q_text, a_text):\n                    continue\n\n                context_chunks = [\n                    {\n                        \"text\": clean_text(question['body']),\n                        \"contains_answer\": False,\n                        \"score\": 0.3,\n                        \"source\": \"stackoverflow_question\"\n                    },\n                    {\n                        \"text\": a_text,\n                        \"contains_answer\": True,\n                        \"score\": 1.0,\n                        \"source\": \"stackoverflow\"\n                    }\n                ]\n\n                processed_data.append({\n                    \"question\": q_text,\n                    \"expected_answer\": a_text,\n                    \"context_chunks\": context_chunks,\n                    \"metadata\": {\n                        \"tags\": question.get('tags', []),\n                        \"question_score\": question.get('score', 0),\n                        \"answer_score\": best_answer.get('score', 0),\n                        \"created\": datetime.fromtimestamp(question['creation_date']).isoformat(),\n                        \"question_id\": question['question_id'],\n                        \"answer_id\": best_answer['answer_id']\n                    }\n                })\n\n                print(f\"✓ {len(processed_data)} / {TOTAL_QUESTIONS}: {q_text[:50]}\")\n\n            except Exception as e:\n                print(f\"Skipping question {question.get('question_id')}: {e}\")\n                continue\n\n        time.sleep(2)\n\n    except Exception as e:\n        print(f\"Batch error {i}-{i+batch_size}: {e}\")\n        time.sleep(10)\n        continue\n\n# Save output\nif processed_data:\n    with open(OUTPUT_PATH, 'w', encoding='utf-8') as f:\n        json.dump(processed_data, f, indent=2, ensure_ascii=False)\n    print(f\"\\n✅ Saved {len(processed_data)} simple Q&A pairs to {OUTPUT_PATH}\")\nelse:\n    print(\"\\n❌ No suitable Q&A found.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T02:24:32.221579Z","iopub.execute_input":"2025-06-23T02:24:32.221920Z","iopub.status.idle":"2025-06-23T02:44:20.065421Z","shell.execute_reply.started":"2025-06-23T02:24:32.221891Z","shell.execute_reply":"2025-06-23T02:44:20.064596Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datasets import load_dataset\n\n# Load ONLY the first shard in streaming mode (no full download)\nds = load_dataset(\"nomic-ai/cornstack-python-v1\", streaming=True, split=\"train\")\n\n# Get the first row\nfirst_row = next(iter(ds))\nprint(\"First row:\")\nprint(first_row)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}